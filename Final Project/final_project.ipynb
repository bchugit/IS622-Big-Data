{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS622 Final Project\n",
    "### Brian Chu | Dec15, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Path for Spark source folder\n",
    "os.environ['SPARK_HOME']=\"/home/brian/workspace/cuny_msda_is622/spark-1.5.1-bin-hadoop2.6\"\n",
    "\n",
    "# Append pyspark to Python Path\n",
    "sys.path.append(\"/home/brian/workspace/cuny_msda_is622/spark-1.5.1-bin-hadoop2.6/python/\")\n",
    "\n",
    "# Append py4j to Python Path\n",
    "sys.path.append(\"/home/brian/workspace/cuny_msda_is622/spark-1.5.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip\")\n",
    "\n",
    "# Launch Spark\n",
    "execfile(\"/home/brian/workspace/cuny_msda_is622/spark-1.5.1-bin-hadoop2.6/python/pyspark/shell.py\")\n",
    "\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "from pyspark.sql import SQLContext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Jester Online Joke Recommender System\n",
    "**http://eigentaste.berkeley.edu/dataset/**  \n",
    "Eigentaste: A Constant Time Collaborative Filtering Algorithm. Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. Information Retrieval, 4(2), 133-151. July 2001.  \n",
    "  \n",
    "This dataset includes ratings from [-10, 10] of up to 100 jokes by 24,983 users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "jester = sc.textFile(\"jester2.csv\")\n",
    "\n",
    "# Create RDD, DataFrame, and Pandas objects\n",
    "jrdd = jester.map(lambda line: line.split(\",\"))\n",
    "jdf = jrdd.toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode missing data (99) to NaN. I found this easier to do in pandas and then reconvert to PySpark dataframe. Perhaps because dataframes are immutable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 99 to NaN (in pandas, remake DF)\n",
    "sqlc = SQLContext(sc)\n",
    "jpd = jdf.toPandas()\n",
    "jpd.iloc[:,1:] = jpd.iloc[:,1:].astype(float)\n",
    "# jpd = jpd.astype(float)\n",
    "# jpd[jpd==99.] = np.nan\n",
    "# jpd[jpd==99.] = 0\n",
    "# jpd = jpd.set_index('_1', drop=True)\n",
    "# jpd = jpd.astype(float)\n",
    "jdf = sqlc.createDataFrame(jpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>_3</th>\n",
       "      <th>_4</th>\n",
       "      <th>_5</th>\n",
       "      <th>_6</th>\n",
       "      <th>_7</th>\n",
       "      <th>_8</th>\n",
       "      <th>_9</th>\n",
       "      <th>_10</th>\n",
       "      <th>...</th>\n",
       "      <th>_92</th>\n",
       "      <th>_93</th>\n",
       "      <th>_94</th>\n",
       "      <th>_95</th>\n",
       "      <th>_96</th>\n",
       "      <th>_97</th>\n",
       "      <th>_98</th>\n",
       "      <th>_99</th>\n",
       "      <th>_100</th>\n",
       "      <th>_101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.12541</td>\n",
       "      <td>0.140966</td>\n",
       "      <td>-0.154918</td>\n",
       "      <td>-0.130863</td>\n",
       "      <td>-0.120599</td>\n",
       "      <td>-0.136315</td>\n",
       "      <td>-0.157965</td>\n",
       "      <td>0.0668746</td>\n",
       "      <td>-0.144013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0452246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0902888</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0731198</td>\n",
       "      <td>-0.00519724</td>\n",
       "      <td>0.113981</td>\n",
       "      <td>0.0783171</td>\n",
       "      <td>-0.0426532</td>\n",
       "      <td>-0.173122</td>\n",
       "      <td>-0.0130827</td>\n",
       "      <td>-0.095701</td>\n",
       "      <td>0.159143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0505387</td>\n",
       "      <td>-0.0887116</td>\n",
       "      <td>-0.00519724</td>\n",
       "      <td>0.140863</td>\n",
       "      <td>-0.00340509</td>\n",
       "      <td>-0.0383521</td>\n",
       "      <td>0.0548399</td>\n",
       "      <td>0.00609332</td>\n",
       "      <td>-0.077421</td>\n",
       "      <td>0.019176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.164915</td>\n",
       "      <td>0.160645</td>\n",
       "      <td>0.164915</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.215072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0463628</td>\n",
       "      <td>0.210178</td>\n",
       "      <td>-0.0726351</td>\n",
       "      <td>0.159952</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0136513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.164344</td>\n",
       "      <td>0.0891326</td>\n",
       "      <td>-0.0806254</td>\n",
       "      <td>-0.104214</td>\n",
       "      <td>0.0262951</td>\n",
       "      <td>0.0309354</td>\n",
       "      <td>0.136116</td>\n",
       "      <td>0.0891326</td>\n",
       "      <td>-0.00850723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100347</td>\n",
       "      <td>0.107887</td>\n",
       "      <td>0.0825588</td>\n",
       "      <td>0.100347</td>\n",
       "      <td>0.110787</td>\n",
       "      <td>0.0299687</td>\n",
       "      <td>0.0601307</td>\n",
       "      <td>0.126642</td>\n",
       "      <td>0.0348023</td>\n",
       "      <td>0.0309354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.107365</td>\n",
       "      <td>-0.0615998</td>\n",
       "      <td>0.00765647</td>\n",
       "      <td>-0.147909</td>\n",
       "      <td>-0.123374</td>\n",
       "      <td>-0.0751727</td>\n",
       "      <td>-0.151215</td>\n",
       "      <td>-0.0151389</td>\n",
       "      <td>-0.115717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0615998</td>\n",
       "      <td>-0.119893</td>\n",
       "      <td>-0.0118327</td>\n",
       "      <td>-0.0515072</td>\n",
       "      <td>-0.0379343</td>\n",
       "      <td>-0.0582936</td>\n",
       "      <td>0.000870054</td>\n",
       "      <td>-0.158002</td>\n",
       "      <td>-0.0878754</td>\n",
       "      <td>-0.0600337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20878</td>\n",
       "      <td>-0.239404</td>\n",
       "      <td>0.187634</td>\n",
       "      <td>0.213641</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0566306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.119504</td>\n",
       "      <td>0.0552093</td>\n",
       "      <td>0.160212</td>\n",
       "      <td>-0.108497</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>-0.0297012</td>\n",
       "      <td>0.161959</td>\n",
       "      <td>0.0246345</td>\n",
       "      <td>-0.0906761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126318</td>\n",
       "      <td>-0.0195679</td>\n",
       "      <td>-0.00174713</td>\n",
       "      <td>-0.099237</td>\n",
       "      <td>-0.0552093</td>\n",
       "      <td>-0.0585289</td>\n",
       "      <td>0.0373886</td>\n",
       "      <td>-0.000873565</td>\n",
       "      <td>0.0228874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.094115</td>\n",
       "      <td>-0.0879069</td>\n",
       "      <td>-0.233922</td>\n",
       "      <td>-0.171096</td>\n",
       "      <td>-0.217036</td>\n",
       "      <td>-0.00720141</td>\n",
       "      <td>-0.131364</td>\n",
       "      <td>-0.221754</td>\n",
       "      <td>-0.195183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108518</td>\n",
       "      <td>-0.00720141</td>\n",
       "      <td>0.103551</td>\n",
       "      <td>-0.00720141</td>\n",
       "      <td>-0.00720141</td>\n",
       "      <td>-0.00720141</td>\n",
       "      <td>-0.00720141</td>\n",
       "      <td>-0.00720141</td>\n",
       "      <td>-0.0844304</td>\n",
       "      <td>-0.122921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0685803</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>0.0685803</td>\n",
       "      <td>0.146046</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>0.203463</td>\n",
       "      <td>0.0574161</td>\n",
       "      <td>0.0685803</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.0882324</td>\n",
       "      <td>0.123707</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.173736</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0751946</td>\n",
       "      <td>-0.160395</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0418813</td>\n",
       "      <td>0.0575468</td>\n",
       "      <td>0.0821641</td>\n",
       "      <td>-0.0760897</td>\n",
       "      <td>0.0233384</td>\n",
       "      <td>0.0233384</td>\n",
       "      <td>-0.0310113</td>\n",
       "      <td>0.159852</td>\n",
       "      <td>-0.231146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0466769</td>\n",
       "      <td>0.0543498</td>\n",
       "      <td>0.00927143</td>\n",
       "      <td>-0.105503</td>\n",
       "      <td>0.110298</td>\n",
       "      <td>0.173919</td>\n",
       "      <td>0.130439</td>\n",
       "      <td>0.0792867</td>\n",
       "      <td>0.144187</td>\n",
       "      <td>0.148982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135027</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128356</td>\n",
       "      <td>0.0121915</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.125698</td>\n",
       "      <td>0.12638</td>\n",
       "      <td>0.125698</td>\n",
       "      <td>0.113156</td>\n",
       "      <td>0.101295</td>\n",
       "      <td>0.00599861</td>\n",
       "      <td>0.0477163</td>\n",
       "      <td>0.111247</td>\n",
       "      <td>0.0813903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110565</td>\n",
       "      <td>-0.0139059</td>\n",
       "      <td>0.0760733</td>\n",
       "      <td>0.0932512</td>\n",
       "      <td>0.0753917</td>\n",
       "      <td>-0.0807086</td>\n",
       "      <td>0.111792</td>\n",
       "      <td>0.122426</td>\n",
       "      <td>-0.111247</td>\n",
       "      <td>0.0886159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.14778</td>\n",
       "      <td>-0.0971753</td>\n",
       "      <td>0.10121</td>\n",
       "      <td>0.0620375</td>\n",
       "      <td>0.130632</td>\n",
       "      <td>-0.0980159</td>\n",
       "      <td>0.146099</td>\n",
       "      <td>0.144418</td>\n",
       "      <td>-0.099529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0457295</td>\n",
       "      <td>-0.0922997</td>\n",
       "      <td>-0.144418</td>\n",
       "      <td>0.146099</td>\n",
       "      <td>-0.14694</td>\n",
       "      <td>-0.0506051</td>\n",
       "      <td>0.139542</td>\n",
       "      <td>-0.0808673</td>\n",
       "      <td>-0.0400134</td>\n",
       "      <td>-0.10037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.0883851</td>\n",
       "      <td>0.039142</td>\n",
       "      <td>0.0588392</td>\n",
       "      <td>-0.104294</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>-0.0575766</td>\n",
       "      <td>-0.0747485</td>\n",
       "      <td>-0.0123739</td>\n",
       "      <td>0.0734859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0785365</td>\n",
       "      <td>0.0429299</td>\n",
       "      <td>0.00606069</td>\n",
       "      <td>-0.149497</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>-0.0343439</td>\n",
       "      <td>0.0944458</td>\n",
       "      <td>0.0712131</td>\n",
       "      <td>-0.0722232</td>\n",
       "      <td>0.0871224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.259417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.206526</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244585</td>\n",
       "      <td>-0.176582</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0694613</td>\n",
       "      <td>0.167498</td>\n",
       "      <td>0.0833095</td>\n",
       "      <td>0.181347</td>\n",
       "      <td>0.0927615</td>\n",
       "      <td>0.167498</td>\n",
       "      <td>0.0534148</td>\n",
       "      <td>0.021322</td>\n",
       "      <td>0.0116501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0182446</td>\n",
       "      <td>0.124854</td>\n",
       "      <td>0.0811114</td>\n",
       "      <td>0.00417647</td>\n",
       "      <td>0.00637461</td>\n",
       "      <td>0.0789133</td>\n",
       "      <td>0.0107709</td>\n",
       "      <td>0.17717</td>\n",
       "      <td>0.0107709</td>\n",
       "      <td>0.167498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.189518</td>\n",
       "      <td>0.163471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185476</td>\n",
       "      <td>-0.233081</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00224548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0741007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.207362</td>\n",
       "      <td>0.0583206</td>\n",
       "      <td>0.214322</td>\n",
       "      <td>-0.158402</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.135279</td>\n",
       "      <td>-0.0384255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135279</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222131</td>\n",
       "      <td>0.140543</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0689554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0536904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.24357</td>\n",
       "      <td>0.180336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.14119</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298775</td>\n",
       "      <td>0.117101</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0518591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00970266</td>\n",
       "      <td>-0.154239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.059137</td>\n",
       "      <td>0.0906622</td>\n",
       "      <td>0.14132</td>\n",
       "      <td>-0.076965</td>\n",
       "      <td>-0.0717471</td>\n",
       "      <td>0.0621808</td>\n",
       "      <td>0.15306</td>\n",
       "      <td>0.107621</td>\n",
       "      <td>0.134145</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0728341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0580499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0397537</td>\n",
       "      <td>-0.143988</td>\n",
       "      <td>0.0793173</td>\n",
       "      <td>-0.159776</td>\n",
       "      <td>-0.120022</td>\n",
       "      <td>0.101572</td>\n",
       "      <td>-0.0987186</td>\n",
       "      <td>-0.0960557</td>\n",
       "      <td>-0.155972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058204</td>\n",
       "      <td>0.156923</td>\n",
       "      <td>0.161678</td>\n",
       "      <td>-0.180889</td>\n",
       "      <td>0.160727</td>\n",
       "      <td>0.155211</td>\n",
       "      <td>0.148744</td>\n",
       "      <td>0.161678</td>\n",
       "      <td>0.158825</td>\n",
       "      <td>-0.158825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.107048</td>\n",
       "      <td>-0.0318691</td>\n",
       "      <td>0.0621039</td>\n",
       "      <td>-0.011985</td>\n",
       "      <td>-0.0621039</td>\n",
       "      <td>0.0648278</td>\n",
       "      <td>-0.107048</td>\n",
       "      <td>0.122846</td>\n",
       "      <td>-0.00926112</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0408579</td>\n",
       "      <td>-0.165338</td>\n",
       "      <td>0.0343206</td>\n",
       "      <td>0.00272386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127596</td>\n",
       "      <td>0.0801835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00348624</td>\n",
       "      <td>0.11063</td>\n",
       "      <td>0.00232416</td>\n",
       "      <td>0.0959878</td>\n",
       "      <td>0.186165</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158212</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132436</td>\n",
       "      <td>0.0645885</td>\n",
       "      <td>-0.117918</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0111239</td>\n",
       "      <td>0.00340527</td>\n",
       "      <td>0.00340527</td>\n",
       "      <td>-0.217029</td>\n",
       "      <td>-0.22157</td>\n",
       "      <td>-0.218164</td>\n",
       "      <td>0.00658352</td>\n",
       "      <td>0.037458</td>\n",
       "      <td>-0.104655</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0220208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0426854</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221713</td>\n",
       "      <td>-0.0474562</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00602618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0155549</td>\n",
       "      <td>0.0806025</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24953</th>\n",
       "      <td>24954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162834</td>\n",
       "      <td>0.0767155</td>\n",
       "      <td>0.061116</td>\n",
       "      <td>0.0155995</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24954</th>\n",
       "      <td>24955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0397997</td>\n",
       "      <td>0.0646289</td>\n",
       "      <td>0.10096</td>\n",
       "      <td>0.156825</td>\n",
       "      <td>-0.102786</td>\n",
       "      <td>0.0744875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24955</th>\n",
       "      <td>24956</td>\n",
       "      <td>-0.0704239</td>\n",
       "      <td>-0.0534422</td>\n",
       "      <td>-0.0824109</td>\n",
       "      <td>-0.192792</td>\n",
       "      <td>-0.0254725</td>\n",
       "      <td>-0.155082</td>\n",
       "      <td>0.0556898</td>\n",
       "      <td>-0.204779</td>\n",
       "      <td>-0.213269</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0836596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24956</th>\n",
       "      <td>24957</td>\n",
       "      <td>0.0967331</td>\n",
       "      <td>0.245385</td>\n",
       "      <td>0.185815</td>\n",
       "      <td>-0.0330642</td>\n",
       "      <td>0.221612</td>\n",
       "      <td>-0.00273257</td>\n",
       "      <td>0.102198</td>\n",
       "      <td>0.0595701</td>\n",
       "      <td>-0.00519189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0571108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24957</th>\n",
       "      <td>24958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.163784</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0669827</td>\n",
       "      <td>0.102851</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0419182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24958</th>\n",
       "      <td>24959</td>\n",
       "      <td>-0.0688573</td>\n",
       "      <td>-0.0447218</td>\n",
       "      <td>-0.0676742</td>\n",
       "      <td>-0.047088</td>\n",
       "      <td>-0.177941</td>\n",
       "      <td>-0.110266</td>\n",
       "      <td>-0.177941</td>\n",
       "      <td>0.142447</td>\n",
       "      <td>-0.0906267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134402</td>\n",
       "      <td>-0.134402</td>\n",
       "      <td>-0.0667277</td>\n",
       "      <td>-0.109083</td>\n",
       "      <td>-0.103404</td>\n",
       "      <td>-0.0929929</td>\n",
       "      <td>-0.00354935</td>\n",
       "      <td>-0.0205862</td>\n",
       "      <td>-0.047088</td>\n",
       "      <td>-0.0425922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24959</th>\n",
       "      <td>24960</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.235508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00913067</td>\n",
       "      <td>-0.0321148</td>\n",
       "      <td>0.21095</td>\n",
       "      <td>0.252195</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0368375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24960</th>\n",
       "      <td>24961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0111802</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20325</td>\n",
       "      <td>0.20583</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.143336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.19207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24961</th>\n",
       "      <td>24962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.126874</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0538709</td>\n",
       "      <td>-0.10019</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090624</td>\n",
       "      <td>-0.209946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24962</th>\n",
       "      <td>24963</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>0.0708305</td>\n",
       "      <td>0.0763786</td>\n",
       "      <td>-0.10227</td>\n",
       "      <td>0.0395763</td>\n",
       "      <td>-0.0861802</td>\n",
       "      <td>0.00184936</td>\n",
       "      <td>-0.0323638</td>\n",
       "      <td>0.00813719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153497</td>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-0.0987558</td>\n",
       "      <td>-0.0647276</td>\n",
       "      <td>0.037727</td>\n",
       "      <td>-0.116695</td>\n",
       "      <td>-0.0817417</td>\n",
       "      <td>0.0565904</td>\n",
       "      <td>-0.0233019</td>\n",
       "      <td>-0.117619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24963</th>\n",
       "      <td>24964</td>\n",
       "      <td>0.126571</td>\n",
       "      <td>0.116644</td>\n",
       "      <td>0.116644</td>\n",
       "      <td>0.126571</td>\n",
       "      <td>0.02792</td>\n",
       "      <td>0.131069</td>\n",
       "      <td>0.117419</td>\n",
       "      <td>0.117419</td>\n",
       "      <td>0.126571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24964</th>\n",
       "      <td>24965</td>\n",
       "      <td>-0.0535642</td>\n",
       "      <td>0.0384432</td>\n",
       "      <td>0.00615091</td>\n",
       "      <td>-0.206568</td>\n",
       "      <td>0.0448504</td>\n",
       "      <td>0.0361366</td>\n",
       "      <td>-0.162999</td>\n",
       "      <td>-0.197854</td>\n",
       "      <td>-0.15813</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.154285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24965</th>\n",
       "      <td>24966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.31228</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0405498</td>\n",
       "      <td>-0.407362</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0405498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24966</th>\n",
       "      <td>24967</td>\n",
       "      <td>0.0704509</td>\n",
       "      <td>0.155743</td>\n",
       "      <td>0.123332</td>\n",
       "      <td>0.069598</td>\n",
       "      <td>0.0504927</td>\n",
       "      <td>0.0902386</td>\n",
       "      <td>0.103544</td>\n",
       "      <td>0.112585</td>\n",
       "      <td>0.0927974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14909</td>\n",
       "      <td>0.147384</td>\n",
       "      <td>0.14329</td>\n",
       "      <td>0.13749</td>\n",
       "      <td>0.0438399</td>\n",
       "      <td>0.0530514</td>\n",
       "      <td>0.140731</td>\n",
       "      <td>0.142437</td>\n",
       "      <td>-0.00579984</td>\n",
       "      <td>0.144996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24967</th>\n",
       "      <td>24968</td>\n",
       "      <td>-0.0170602</td>\n",
       "      <td>-0.0170602</td>\n",
       "      <td>-0.0170602</td>\n",
       "      <td>-0.0170602</td>\n",
       "      <td>-0.108244</td>\n",
       "      <td>0.00588284</td>\n",
       "      <td>-0.177073</td>\n",
       "      <td>-0.0170602</td>\n",
       "      <td>0.0288259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0170602</td>\n",
       "      <td>0.0511807</td>\n",
       "      <td>0.22296</td>\n",
       "      <td>0.0400033</td>\n",
       "      <td>0.0511807</td>\n",
       "      <td>0.245314</td>\n",
       "      <td>0.0170602</td>\n",
       "      <td>0.0858894</td>\n",
       "      <td>-0.0170602</td>\n",
       "      <td>-0.0400033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24968</th>\n",
       "      <td>24969</td>\n",
       "      <td>0.176676</td>\n",
       "      <td>0.18543</td>\n",
       "      <td>0.163147</td>\n",
       "      <td>0.0676463</td>\n",
       "      <td>0.00875423</td>\n",
       "      <td>0.156382</td>\n",
       "      <td>0.044368</td>\n",
       "      <td>0.0250689</td>\n",
       "      <td>0.116789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0358127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24969</th>\n",
       "      <td>24970</td>\n",
       "      <td>0.160045</td>\n",
       "      <td>0.0279642</td>\n",
       "      <td>-0.128585</td>\n",
       "      <td>-0.17927</td>\n",
       "      <td>-0.184264</td>\n",
       "      <td>0.0267158</td>\n",
       "      <td>0.0569271</td>\n",
       "      <td>-0.0521832</td>\n",
       "      <td>-0.157548</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0387005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>24971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00307107</td>\n",
       "      <td>-0.129599</td>\n",
       "      <td>0.0448376</td>\n",
       "      <td>0.271175</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>24972</td>\n",
       "      <td>0.0796685</td>\n",
       "      <td>0.0796685</td>\n",
       "      <td>0.17252</td>\n",
       "      <td>-0.0055405</td>\n",
       "      <td>0.0389745</td>\n",
       "      <td>0.0724086</td>\n",
       "      <td>0.150167</td>\n",
       "      <td>-0.150167</td>\n",
       "      <td>0.0796685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0129915</td>\n",
       "      <td>0.139086</td>\n",
       "      <td>0.0945706</td>\n",
       "      <td>-0.179971</td>\n",
       "      <td>0.0611365</td>\n",
       "      <td>-0.0426045</td>\n",
       "      <td>0.113103</td>\n",
       "      <td>-0.0055405</td>\n",
       "      <td>-0.0055405</td>\n",
       "      <td>0.0834896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>24973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159159</td>\n",
       "      <td>-0.216794</td>\n",
       "      <td>-0.103903</td>\n",
       "      <td>0.0666246</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>24974</td>\n",
       "      <td>0.0342048</td>\n",
       "      <td>-0.179005</td>\n",
       "      <td>-0.155822</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162283</td>\n",
       "      <td>-0.000950134</td>\n",
       "      <td>-0.021283</td>\n",
       "      <td>-0.160573</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.118007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.07107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>24975</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.167161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108237</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>-0.0598297</td>\n",
       "      <td>0.0995349</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>24976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168409</td>\n",
       "      <td>0.160937</td>\n",
       "      <td>0.173966</td>\n",
       "      <td>0.0400427</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>24977</td>\n",
       "      <td>0.0257455</td>\n",
       "      <td>0.0331284</td>\n",
       "      <td>0.0450547</td>\n",
       "      <td>0.0348322</td>\n",
       "      <td>0.0882163</td>\n",
       "      <td>0.0946527</td>\n",
       "      <td>-0.0035968</td>\n",
       "      <td>-0.00454333</td>\n",
       "      <td>0.172836</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17454</td>\n",
       "      <td>0.170943</td>\n",
       "      <td>-0.00643638</td>\n",
       "      <td>0.176433</td>\n",
       "      <td>0.173593</td>\n",
       "      <td>0.168103</td>\n",
       "      <td>0.175486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>24978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0299711</td>\n",
       "      <td>-0.109894</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>24979</td>\n",
       "      <td>0.00670929</td>\n",
       "      <td>0.113296</td>\n",
       "      <td>0.138455</td>\n",
       "      <td>0.0355288</td>\n",
       "      <td>0.0487949</td>\n",
       "      <td>0.102927</td>\n",
       "      <td>-0.134033</td>\n",
       "      <td>-0.00808165</td>\n",
       "      <td>-0.133271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134643</td>\n",
       "      <td>-0.0184506</td>\n",
       "      <td>0.14059</td>\n",
       "      <td>-0.102164</td>\n",
       "      <td>0.128849</td>\n",
       "      <td>0.137693</td>\n",
       "      <td>0.099877</td>\n",
       "      <td>0.132509</td>\n",
       "      <td>0.134033</td>\n",
       "      <td>0.113296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>24980</td>\n",
       "      <td>0.136635</td>\n",
       "      <td>-0.122118</td>\n",
       "      <td>0.128553</td>\n",
       "      <td>0.135886</td>\n",
       "      <td>0.01302</td>\n",
       "      <td>-0.133642</td>\n",
       "      <td>-0.0523791</td>\n",
       "      <td>0.0865004</td>\n",
       "      <td>-0.12137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0175096</td>\n",
       "      <td>-0.0857521</td>\n",
       "      <td>-0.0218496</td>\n",
       "      <td>0.00359171</td>\n",
       "      <td>0.137982</td>\n",
       "      <td>-0.122717</td>\n",
       "      <td>-0.1082</td>\n",
       "      <td>-0.128553</td>\n",
       "      <td>0.136635</td>\n",
       "      <td>0.126458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>24981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.241181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207968</td>\n",
       "      <td>-0.20952</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>24982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.315765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148289</td>\n",
       "      <td>-0.269912</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>24983</td>\n",
       "      <td>0.0531694</td>\n",
       "      <td>0.0584207</td>\n",
       "      <td>-0.0870841</td>\n",
       "      <td>0.0934294</td>\n",
       "      <td>-0.0498874</td>\n",
       "      <td>0.160384</td>\n",
       "      <td>0.0509814</td>\n",
       "      <td>0.0997747</td>\n",
       "      <td>0.147693</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24983 rows  101 columns</p>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "jpd = jdf.toPandas()\n",
    "jpd.iloc[:,1:] = jpd.iloc[:,1:].astype(float)\n",
    "jpd[jpd==99.] = 0\n",
    "jpd.iloc[:,1:] = preprocessing.normalize(jpd.iloc[:,1:])\n",
    "jpd\n",
    "\n",
    "jdf = sqlc.createDataFrame(jpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf2 = jrdd.toDF()\n",
    "jpd2 = jdf2.toPandas()\n",
    "jpd2.iloc[:,1:] = jpd2.iloc[:,1:].astype(float)\n",
    "jpd2[jpd2==99.] = 0\n",
    "jdf2 = sqlc.createDataFrame(jpd2)\n",
    "\n",
    "from pyspark.mllib.feature import StandardScaler\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "normalizer1 = Normalizer()\n",
    "norm_jdf2 = normalizer1.transform(jdf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Recommendations\n",
    "\n",
    "### PySpark MLlib  \n",
    "I am going to use PySpark's MLlib package, which incorporates collaborative filtering using the Alternating Least Squares (ALS) algorithm to predict missing entries. ALS aims to minimize the squared error of the UV user-item rating matrix by alternating learning sequences of U to V and V to U until a steady-state has been reached. This is similar to the collaborative filtering theory discussed in the MMS text.  \n",
    "  \n",
    "### Modified source code:  \n",
    "http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html  \n",
    "https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLlib ALS requires a Ratings object, which is a tuple in the format (userID, itemID, itemRating)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1', 1, -0.12541000876329006),\n",
       " (u'1', 2, 0.1409659817173043),\n",
       " (u'1', 3, -0.1549182461193583),\n",
       " (u'1', 4, -0.13086261783995484),\n",
       " (u'1', 5, -0.12059888310740936)]"
      ]
     },
     "execution_count": 683,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Create Ratings object required for MLlib ALS train function\n",
    "# Exclude NaN entries for model training; will be used for testing and predicting\n",
    "# ratings = jdf.flatMap(lambda line: [(line[0], i, line[i]) for i in range(1,101) if np.isnan(line[i])==0])\n",
    "ratings = jdf.flatMap(lambda line: [(line[0], i, line[i]) for i in range(1,101) if line[i]!=0])\n",
    "\n",
    "# View snippet of Ratings object\n",
    "ratings.collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the number of users, jokes, and ratings in our dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1805072 ratings from 24983 users on 100 jokes.\n"
     ]
    }
   ],
   "source": [
    "numRatings = ratings.count()\n",
    "numUsers = ratings.map(lambda r: r[0]).distinct().count()\n",
    "numJokes = ratings.map(lambda r: r[1]).distinct().count()\n",
    "\n",
    "print \"Got %d ratings from %d users on %d jokes.\" % (numRatings, numUsers, numJokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly divide ratings into a 75% training and 25% testing set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated Jokes for All Users\n",
      "Training set: 1353794\n",
      "Test set: 451278\n"
     ]
    }
   ],
   "source": [
    "ratingsTrain, ratingsTest = ratings.randomSplit([0.75, 0.25], seed = 85)\n",
    "\n",
    "# Check number of ratings in each set\n",
    "print \"Rated Jokes for All Users\"\n",
    "print \"Training set: %d\" %(len(ratingsTrain.collect()))\n",
    "print \"Test set: %d\" %(len(ratingsTest.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the recommendation model using ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "\n",
    "# Default parameters; can also tune using function defined in MLlib example\n",
    "rank = 5\n",
    "numIterations = 10\n",
    "\n",
    "# Train model with training data\n",
    "cf_model = ALS.train(ratingsTrain, rank, numIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check model accuracy and error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((5993, 77), (0.0704940933797176, -0.02550462374990562)),\n",
       " ((17350, 18), (0.17554646970416904, 0.005708623905954488)),\n",
       " ((21952, 22), (0.10988728506862236, 0.07990360094054466))]"
      ]
     },
     "execution_count": 687,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "ratingsTest = sc.parallelize(ratingsTest.collect())\n",
    "cf_test = cf_model.predictAll(ratingsTest.map(lambda p: (p[0], p[1]))).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "# [(userID, jokeID), (actual rating, predicted rating)]\n",
    "cf_results = ratingsTest.map(lambda r: ((int(r[0]), r[1]), r[2])).join(cf_test)\n",
    "cf_results = sc.parallelize(cf_results.collect())\n",
    "\n",
    "# Example\n",
    "cf_results.collect()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.009\n",
      "Root Mean Squared Error = 0.094 \n",
      "\n",
      "Mean Absolute Error = 0.076\n",
      "Normalized Mean Abolute Error = 0.004\n"
     ]
    }
   ],
   "source": [
    "MSE = cf_results.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print \"Mean Squared Error = %.3f\" %(MSE)\n",
    "\n",
    "RMSE = math.sqrt(MSE)\n",
    "print \"Root Mean Squared Error = %.3f \\n\" %(RMSE)\n",
    "\n",
    "MAE = cf_results.map(lambda r: abs((r[1][0] - r[1][1]))).mean()\n",
    "print \"Mean Absolute Error = %.3f\" %(MAE)\n",
    "\n",
    "NMAE = MAE / (10 - -10)\n",
    "print \"Normalized Mean Abolute Error = %.3f\" %(NMAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tinkered with some of the tuning parameters (rank, iterations) and found the RMSE to be fairly consistent. The ratings scale goes from -10 to 10 (range of 20) so both RMSE and MAE may seem somewhat large. However, in the cited paper above, Goldberg et al. looked at a few other algorithms and found the NMAE to range from 0.187 to 0.237. Relatively, the ALS model here would appear very good. Note that NMAE was preferred by the authors to normalize errors as a percentage of the full scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make recommendations using model and set of jokes not rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rated_notRated(user_num):\n",
    "    \n",
    "    jokeID = list(range(1, numJokes + 1))\n",
    "    userID = str(user_num)\n",
    "\n",
    "    # User's rated jokes\n",
    "    uRatings = [(j,r) for (u,j,r) in ratings.collect() if u==userID]\n",
    "    jokes_rated = [j[0] for j in uRatings]\n",
    "    jokes_notRated = [j for j in jokeID if j not in jokes_rated]\n",
    "    \n",
    "    return (jokes_rated, jokes_notRated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated jokes: 74\n",
      "Unrated jokes: 26\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "user = 1\n",
    "u1 = get_rated_notRated(user)\n",
    "print \"Rated jokes: %d\" %(len(u1[0]))\n",
    "print \"Unrated jokes: %d\" %(len(u1[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_recs(user, unratedIDs, model):\n",
    "    \n",
    "    unratedIDs = sc.parallelize(set(unratedIDs))\n",
    "    cf_predictions = model.predictAll(unratedIDs.map(lambda x: (user, x))).collect()\n",
    "    cf_predictions = sorted(cf_predictions, key=lambda k: k[2], reverse=True)\n",
    "    \n",
    "    return cf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank dictionary to hold all recommendations for all users\n",
    "cf_recs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended jokes for User 1225 (score out of 10): \n",
      "\n",
      "JokeID: 89    Predicted rating: 0.02\n",
      "JokeID: 54    Predicted rating: -0.02\n",
      "JokeID: 93    Predicted rating: -0.03\n",
      "JokeID: 76    Predicted rating: -0.03\n",
      "JokeID: 91    Predicted rating: -0.04\n"
     ]
    }
   ],
   "source": [
    "# Example - top 5 recommendations for User 13\n",
    "user_num = 1225\n",
    "user_rated, user_notRated = get_rated_notRated(user_num)\n",
    "\n",
    "if user_notRated:\n",
    "    cf_recs[user_num] = get_cf_recs(user_num, user_notRated, cf_model)\n",
    "    print \"Recommended jokes for User %d (score out of 10): \\n\" %(user_num)\n",
    "    for i in cf_recs[user_num][:5]:\n",
    "        print \"JokeID: %d    Predicted rating: %.2f\" %(i[1], i[2])\n",
    "else: \n",
    "    print \"No unrated jokes for User %d\" %(user_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print full joke of the top 5 recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "jokesFull = pickle.load(open( \"jokesFull.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke #89:\n",
      "Q: How many programmers does it take to change a lightbulb? A: NONE! That's a hardware problem. . . .\n",
      "\n",
      "Joke #54:\n",
      "A woman has twins,  and gives them up for adoption.  One of them goes to a family in Egypt and is named \"Amal. \" The other goes to a family in Spain; they name him \"Juan. \" Years later,  Juan sends a picture of himself to his mom.  Upon receiving the picture,  she tells her husband that she wishes she also had a picture of Amal.  Her husband responds,  \"But they are twins-if you've seen Juan,  you've seen Amal.\n",
      "\n",
      "Joke #93:\n",
      "Two atoms are walking down the street when one atom says to the other \"Oh,  my! I've lost an electron!\" The second atom says\"Are you sure\" The first replies \"I'm positive!\"\n",
      "\n",
      "Joke #76:\n",
      "If pro- is the opposite of con- then congress must be the opposite of progress.\n",
      "\n",
      "Joke #91:\n",
      "Early one morning a mother went to her sleeping son and woke him up.  \"Wake up,  son.  It's time to go to school. \" \"But why,  Mama? I don't want to go to school. \" \"Give me two reasons why you don't want to go to school. \" \"One,  all the children hate me.  Two,  all the teachers hate me, \" \"Oh! that's no reason.  Come on,  you have to go to school, \" \"Give me two good reasons WHY I should go to school?\" \"One,  you are fifty-two years old.  Two,  you are the principal of the school. \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_num = 1225\n",
    "for i in cf_recs[user_num][:5]:\n",
    "    print \"Joke #%d:\" %(i[1])\n",
    "    print jokesFull[i[1]] +\"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering is interesting because while it does not explicitly account for specific content features about the joke itself (e.g. humour type, general topic), it is able to implicitly deduce such latent factors and be effective at recommending similar items. In this example for User 13, it would appear s/he likes lowbrow humour and relationship topics. The downside of collaborative filtering may be that users must rate their tastes consistently but sometimes this is harder to formalize when the 'item' is more abstract like humour. Additionally, if you equally like many genres or content features and rate several items very similarly, ALS and collaborative filtering may be less successful in its recommendations. This would be true with almost any algorithm though.  \n",
    "\n",
    "In the Goldberg paper, the authors assessed a few recommendation methods including k-nearest neighbors, global mean, and their proposed Eigentaste algorithm. The latter involves normalizing the ratings and applying principal component analysis (PCA), amongst other steps. They deduced Eigentaste was more appropriate for sparse matrices and 'capturing tastes with finer granularity'. As Eigentaste is effectively a form of collaborative filtering, it should not be too surprising that the ALS method used in this mini-project appears fairly consistent in model error and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommendations \n",
    "### Create Joke (item) Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.feature import IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get corpus of jokes (documents)\n",
    "* Use cleaned jokes stripped of stopwords and punctuation for better classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokesClean = pickle.load(open( \"jokesClean.p\", \"rb\" ) )\n",
    "\n",
    "# Assemble corpus as one file, split by new line\n",
    "with open('jokesClean.txt', 'w') as jc:\n",
    "    for k,v in jokesClean.iteritems():\n",
    "      jc.write(\"%s\\n\" % v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 698,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Load into Spark - should have 100 jokes\n",
    "documents = sc.textFile(\"jokesClean.txt\").map(lambda line: line.split(\" \"))\n",
    "documents.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction - use PySpark's tf.idf function  \n",
    "* add source and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF()\n",
    "tf = hashingTF.transform(documents)\n",
    "\n",
    "tf.cache()\n",
    "idf = IDF().fit(tf)\n",
    "tfidf = idf.transform(tf)\n",
    "\n",
    "joke_features = tfidf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(1048576, {47054: 3.922, 183558: 7.8439, 285677: 3.922, 397847: 2.2172, 419033: 3.0057, 518276: 1.2478, 582313: 3.5165, 605676: 2.4179, 608735: 3.5638, 611077: 2.3125, 640114: 3.2288, 641573: 3.922, 904615: 6.4577, 985518: 3.922})"
      ]
     },
     "execution_count": 700,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Example\n",
    "jf1 = joke_features[0]\n",
    "jf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate cosine distance (similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_distance(v1, v2):\n",
    "    dotprod = v1.dot(v2)\n",
    "    sqdist = v1.squared_distance(v2)\n",
    "    cosine_angle = dotprod / sqdist\n",
    "    \n",
    "    try:\n",
    "        cosine_distance = math.acos(cosine_angle) * (180/math.pi)\n",
    "    except:\n",
    "        cosine_distance = 90.0\n",
    "    \n",
    "    return np.round(cosine_distance, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n"
     ]
    }
   ],
   "source": [
    "# Test using PySpark sparse vectors\n",
    "sv1 = Vectors.sparse(3, [0,1,2], [1.0,2.0,-1.0])\n",
    "sv2 = Vectors.sparse(3, [0,1,2], [2.0,1.0,1.0])\n",
    "print cosine_distance(sv1, sv2) # should be 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# Example cosine distance Joke 1 and 2\n",
    "jf2 = joke_features[1]\n",
    "print cosine_distance(jf1, jf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n",
      "90.0\n",
      "88.91\n",
      "90.0\n",
      "89.93\n",
      "90.0\n",
      "90.0\n",
      "89.64\n",
      "89.71\n",
      "90.0\n",
      "88.75\n",
      "90.0\n",
      "89.91\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "89.92\n",
      "90.0\n",
      "89.05\n",
      "90.0\n",
      "89.62\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "89.57\n",
      "89.43\n",
      "89.68\n",
      "89.85\n",
      "90.0\n",
      "89.55\n",
      "89.03\n",
      "88.8\n",
      "90.0\n",
      "89.28\n",
      "89.62\n",
      "89.06\n",
      "90.0\n",
      "88.37\n",
      "90.0\n",
      "90.0\n",
      "89.47\n",
      "89.65\n",
      "89.68\n",
      "90.0\n",
      "89.13\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "89.46\n",
      "90.0\n",
      "90.0\n",
      "89.21\n",
      "90.0\n",
      "90.0\n",
      "88.89\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "89.51\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "89.51\n",
      "90.0\n",
      "90.0\n",
      "86.89\n",
      "89.55\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "88.46\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "89.78\n",
      "88.88\n",
      "89.77\n",
      "89.89\n",
      "90.0\n",
      "90.0\n",
      "89.24\n",
      "77.97\n",
      "85.52\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "89.48\n",
      "89.71\n",
      "89.15\n",
      "90.0\n",
      "90.0\n",
      "89.85\n",
      "90.0\n",
      "90.0\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(joke_features)):\n",
    "    print cosine_distance(jf1, joke_features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create User Profile  \n",
    "\n",
    "* Weight rating by each joke's features\n",
    "* Output - sparse vector of user feature rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add two sparse vectors together - needed to aggregate user features for all jokes\n",
    "# http://stackoverflow.com/questions/32981875/how-to-add-two-sparse-vectors-in-spark-using-python\n",
    "\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "\n",
    "def add(v1, v2):\n",
    "    \"\"\"Add two sparse vectors\n",
    "    >>> v1 = Vectors.sparse(3, {0: 1.0, 2: 1.0})\n",
    "    >>> v2 = Vectors.sparse(3, {1: 1.0})\n",
    "    >>> add(v1, v2)\n",
    "    SparseVector(3, {0: 1.0, 1: 1.0, 2: 1.0})\n",
    "    \"\"\"\n",
    "    assert isinstance(v1, SparseVector) and isinstance(v2, SparseVector)\n",
    "    assert v1.size == v2.size \n",
    "    # Compute union of indices\n",
    "    indices = set(v1.indices).union(set(v2.indices))\n",
    "    # Not particularly efficient but we are limited by SPARK-10973\n",
    "    # Create index: value dicts\n",
    "    v1d = dict(zip(v1.indices, v1.values))\n",
    "    v2d = dict(zip(v2.indices, v2.values))\n",
    "    zero = np.float64(0)\n",
    "    # Create dictionary index: (v1[index] + v2[index])\n",
    "    values =  {i: v1d.get(i, zero) + v2d.get(i, zero)\n",
    "       for i in indices\n",
    "       if v1d.get(i, zero) + v2d.get(i, zero) != zero}\n",
    "\n",
    "    return Vectors.sparse(v1.size, values)\n",
    "\n",
    "SparseVector.__add__ = add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User profile based on rated jokes\n",
    "def get_user_profile(user_num):\n",
    "    features = tfidf.collect()\n",
    "    user_profile = features[0]\n",
    "    user_ratings = jdf.collect()[user_num - 1]\n",
    "    for i in range(1, len(features)):\n",
    "        if user_ratings[i] != 0:\n",
    "            features[i].values = features[i].values * user_ratings[i+1]\n",
    "            user_profile = user_profile + features[i]\n",
    "    return user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make recommendations  \n",
    "* User-Item profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content-based recommendations\n",
    "def content_recommend(user_profile, user_notRated):\n",
    "    \n",
    "    # Similarity - all jokes\n",
    "    similarity_all = [{i+1 : cosine_distance(joke_features[i], user_profile)} for i in range(len(jokes))]\n",
    "\n",
    "    # Similarity - not rated jokes only\n",
    "    notRated = sc.parallelize(set(user_notRated))\n",
    "    similarity_notRated = notRated.map(lambda x: (x, similarity_all[x-1][x])).collect()\n",
    "    similarity_notRated = sorted(similarity_notRated , key=lambda k: k[1])\n",
    "    return similarity_notRated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank dictionary to hold all recommendations for all users\n",
    "content_recs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended jokes for User 1225: \n",
      "\n",
      "JokeID: 87    Similarity distance: 79.77\n",
      "JokeID: 88    Similarity distance: 86.32\n",
      "JokeID: 33    Similarity distance: 88.75\n",
      "JokeID: 39    Similarity distance: 88.96\n",
      "JokeID: 76    Similarity distance: 89.08\n"
     ]
    }
   ],
   "source": [
    "# Example - top 5 recommendations for User 13\n",
    "user_num = 1225\n",
    "user_rated, user_notRated = get_rated_notRated(user_num)\n",
    "\n",
    "if user_notRated:\n",
    "    up = get_user_profile(user_num)\n",
    "    content_recs[user_num] = content_recommend(up, user_notRated)\n",
    "    print \"Recommended jokes for User %d: \\n\" %(user_num)\n",
    "    for i in content_recs[user_num][:5]:       \n",
    "        print \"JokeID: %d    Similarity distance: %.2f\" %(i[0], i[1])\n",
    "else: \n",
    "    print \"No unrated jokes for User %d\" %(user_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recommended jokes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke #87:\n",
      "A Czechoslovakian man felt his eyesight was growing steadily worse, and felt it was time to go see an optometrist. The doctor started with some simple testing, and showed him a standard eye chart with letters of diminishing size: CRKBNWXSKZY. . . \"Can you read this?\" the doctor asked. \"Read it?\" the Czech answered. \"Doc, I know him!\"\n",
      "\n",
      "Joke #88:\n",
      "A radio conversation of a US naval ship with Canadian authorities ... Americans: Please divert your course 15 degrees to the North to avoid a collision. Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision. Americans: This is the Captain of a US Navy ship. I say again, divert YOUR course. Canadians: No. I say again, you divert YOUR course. Americans: This is the aircraft carrier USS LINCOLN, the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers, three cruisers and numerous support vessels. I demand that you change your course 15 degrees north, that's ONE FIVE DEGREES NORTH, or counter-measures will be undertaken to ensure the safety of this ship. Canadians: This is a lighthouse. Your call.\n",
      "\n",
      "Joke #93:\n",
      "Two atoms are walking down the street when one atom says to the other \"Oh, my! I've lost an electron!\" The second atom says\"Are you sure\" The first replies \"I'm positive!\"\n",
      "\n",
      "Joke #94:\n",
      "Just a thought .. Before criticizing someone, walk a mile in their shoes. Then when you do criticize them, you will be a mile away and have their shoes !\n",
      "\n",
      "Joke #86:\n",
      "A man, recently completing a routine physical examination receives a phone call from his doctor. The doctor says, \"I have some good news and some bad news.\" The man says, \"OK, give me the good news first.\" The doctor says, \"The good news is, you have 24 hours to live.\" The man replies, \"Shit! That's the good news? Then what's the bad news?\" The doctor says, \"The bad news is, I forgot to call you yesterday.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_num = 1\n",
    "for i in content_recs[user_num][:5]:\n",
    "    print \"Joke #%d:\" %(i[0])\n",
    "    print jokes_text[i[0]] +\"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare CF and CB\n",
    "\n",
    "* test set\n",
    "* pick top N recommendations from CF and CB\n",
    "* compare with top N from test set\n",
    "* calculate precision, recall \n",
    "* top test into function\n",
    "* calculate F1\n",
    "* all in one accuracy function\n",
    "* redo cf model\n",
    "* redo user profile\n",
    "* loop over X users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated Jokes for User 13\n",
      "\n",
      "Total rated: 47\n",
      "Training set: 37\n",
      "Test set: 10\n"
     ]
    }
   ],
   "source": [
    "# Divide ratings into test and training set\n",
    "user_num = 13\n",
    "rall = ratings.filter(lambda x: x[0]==str(user_num))\n",
    "\n",
    "rtrain, rtest = rall.randomSplit([0.75, 0.25], seed = 85)\n",
    "rtrainIDs = [x[1] for x in rtrain.collect()]\n",
    "rtestIDs = [x[1] for x in rtest.collect()]\n",
    "\n",
    "print \"Rated Jokes for User %d\\n\" %(user_num)\n",
    "print \"Total rated: %d\" %(rall.count())\n",
    "print \"Training set: %d\" %(len(rtrainIDs))\n",
    "print \"Test set: %d\" %(len(rtestIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 813,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Top N recommendations (N = 25% of test set)\n",
    "n = int(math.ceil(0.25 * len(rtestIDs)))\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual test set top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top test set results based on actual ratings\n",
    "def get_actual_rec(test_set, n):\n",
    "    test_set = test_set.sortBy(lambda x: x[2], ascending=False)\n",
    "    test_IDs = [x[1] for x in test_set.collect()]\n",
    "    top_IDs = [x[1] for x in test_set.collect()[:n]]\n",
    "    return top_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 36, 93]\n"
     ]
    }
   ],
   "source": [
    "topTestIDs = get_actual_rec(rtest, n)\n",
    "print topTestIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CF top N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: redo training model for rtrainIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_train_ratings = ratings.filter(lambda x: x[1] not in rtestIDs & x[0]!=user_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters; can also tune using function defined in MLlib example\n",
    "rank = 5\n",
    "numIterations = 10\n",
    "\n",
    "# Train model with training data\n",
    "cf_traintest_model = ALS.train(cf_train_ratings, rank, numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 49, 42]\n"
     ]
    }
   ],
   "source": [
    "# Get top CF recommendations\n",
    "compare_cf = get_cf_recs(user_num, rtestIDs, cf_model)\n",
    "topCFIDs = [x[1] for x in compare_cf[:n]]\n",
    "print topCFIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content-based top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update user profile function for train/test purposes\n",
    "# Remove testIDs from user profile since they are equal to 'not rated'\n",
    "def get_user_profile2(user_num, testIDs):\n",
    "    features = tfidf.collect()\n",
    "    user_profile = features[0]\n",
    "    user_ratings = jdf.collect()[user_num - 1]\n",
    "    for i in range(1, len(features)):\n",
    "        if (user_ratings[i] != 0 and i not in testIDs):\n",
    "            features[i].values = features[i].values * user_ratings[i+1]\n",
    "            user_profile = user_profile + features[i]\n",
    "    return user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: redo user profile for rTrainIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 49, 63]\n"
     ]
    }
   ],
   "source": [
    "# Get top content-based recommendations\n",
    "up_comp = get_user_profile2(user_num, rtestIDs)\n",
    "compare_content = get_content_recs(up_comp, rtestIDs)\n",
    "topContentIDs = [x[0] for x in compare_content[:n]]\n",
    "print topContentIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap all of the above into one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_traintest_sets(user_num, N):\n",
    "    \n",
    "    rall = ratings.filter(lambda x: x[0]==str(user_num))\n",
    "    rtrain, rtest = rall.randomSplit([0.75, 0.25], seed = 85)\n",
    "    rtrainIDs = [x[1] for x in rtrain.collect()]\n",
    "    rtestIDs = [x[1] for x in rtest.collect()]\n",
    "    \n",
    "    n = int(math.ceil(N * len(rtestIDs)))\n",
    "    \n",
    "    return(rtrain, rtrainIDs, rtest, rtestIDs, n)\n",
    "\n",
    "def get_top_recommendations(user_num, rtest, rtestIDs, n):\n",
    "       \n",
    "    # top Test\n",
    "    topTestIDs = get_actual_rec(rtest, n)\n",
    "    \n",
    "    # top CF\n",
    "    # TODO: update model\n",
    "    compare_cf = get_cf_recs(user_num, rtestIDs, cf_model)\n",
    "    topCFIDs = [x[1] for x in compare_cf[:n]]\n",
    "    \n",
    "    # top CB\n",
    "    # TODO: update user profile\n",
    "    up_comp = get_user_profile2(user_num, rtestIDs)\n",
    "    compare_content = get_content_recs(up_comp, rtestIDs)\n",
    "    topContentIDs = [x[0] for x in compare_content[:n]]\n",
    "    \n",
    "    return(topTestIDs, topCFIDs, topContentIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 47, 54, 78, 2, 97]\n",
      "[54, 49, 69, 47, 48, 78]\n",
      "[47, 29, 56, 69, 54, 97]\n"
     ]
    }
   ],
   "source": [
    "user_num = 122\n",
    "trainSet, trainIDs, testSet, testIDs, n = make_traintest_sets(user_num)\n",
    "topTestIDs, topCFIDs, topContentIDs = get_top_recommendations(user_num, testSet, testIDs, n)\n",
    "\n",
    "print topTestIDs\n",
    "print topCFIDs\n",
    "print topContentIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Scores\n",
    "\n",
    "**<a href=\"http://grouplens.org/site-content/uploads/evaluating-TOIS-20041.pdf\">Evaluating collaborative filtering recommender systems (2004)</a>**  \n",
    "Jonathan L. Herlocker , Joseph A. Konstan , Loren G. Terveen , John T. Riedl  \n",
    "  \n",
    "**<a href=\"http://research.microsoft.com/pubs/115396/EvaluationMetrics.TR.pdf\">Evaluating Recommendation Systems</a>**  \n",
    "Guy Shani and Asela Gunawardana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation precision, recallm, F1-score\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "def get_rec_accuracy(testRecs, compRecs, numTest, rec_rank=False):\n",
    "    \n",
    "    # Recommendation rank does not matter\n",
    "    if rec_rank:\n",
    "        \n",
    "        rec_precision = sm.precision_score(np.array(testRecs), np.array(compRecs), average='macro')\n",
    "        rec_recall = np.round((rec_precision * len(testRecs)) / float(numTest), 2)\n",
    "        rec_f1 = np.round((2 * rec_precision * rec_recall) / (rec_precision + rec_recall), 2)   \n",
    "\n",
    "    # Recommendation rank matters\n",
    "    else:    \n",
    "        matches = list(set(testRecs).intersection(compRecs))\n",
    "        rec_precision = np.round(len(matches) / float(len(testRecs)), 2)\n",
    "        rec_recall = np.round(len(matches) / float(numTest), 2)\n",
    "        rec_f1 = np.round((2 * rec_precision * rec_recall) / (rec_precision + rec_recall), 2)\n",
    "        \n",
    "    if np.isnan(rec_f1):\n",
    "        rec_f1 = 0\n",
    "    \n",
    "    return (rec_precision, rec_recall, rec_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative filtering accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 122\n",
      "\n",
      "Collaborative Filtering Accuracy - Excluding Recommendation Rank\n",
      "Precision: 0.50\n",
      "Recall: 0.14\n",
      "F1 score: 0.22\n",
      "\n",
      "Collaborative Filtering Accuracy - Including Recommendation Rank\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1 score: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collaborative filtering accuracy\n",
    "numTest = len(testIDs)\n",
    "precisionCF, recallCF, f1CF = get_rec_accuracy(topTestIDs, topCFIDs, numTest, rec_rank=False)\n",
    "print \"User %d\\n\" %user_num\n",
    "print \"Collaborative Filtering Accuracy - Excluding Recommendation Rank\"\n",
    "print \"Precision: %.2f\" %precisionCF\n",
    "print \"Recall: %.2f\" %recallCF\n",
    "print \"F1 score: %.2f\\n\" %f1CF\n",
    "\n",
    "precisionCF_rank, recallCF_rank, f1CF_rank = get_rec_accuracy(topTestIDs, topCFIDs, numTest, rec_rank=True)\n",
    "print \"Collaborative Filtering Accuracy - Including Recommendation Rank\"\n",
    "print \"Precision: %.2f\" %precisionCF_rank\n",
    "print \"Recall: %.2f\" %recallCF_rank\n",
    "print \"F1 score: %.2f\\n\" %f1CF_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content-based accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 122\n",
      "\n",
      "Content-based Accuracy - Excluding Recommendation Rank\n",
      "Precision: 0.67\n",
      "Recall: 0.18\n",
      "F1 score: 0.28\n",
      "\n",
      "Content-based Accuracy - Including Recommendation Rank\n",
      "Precision: 0.12\n",
      "Recall: 0.03\n",
      "F1 score: 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Content-based accuracy\n",
    "numTest = len(testIDs)\n",
    "precisionContent, recallContent, f1Content = get_rec_accuracy(topTestIDs, topContentIDs, numTest, rec_rank=False)\n",
    "print \"User %d\\n\" %user_num\n",
    "print \"Content-based Accuracy - Excluding Recommendation Rank\"\n",
    "print \"Precision: %.2f\" %precisionContent\n",
    "print \"Recall: %.2f\" %recallContent\n",
    "print \"F1 score: %.2f\\n\" %f1Content\n",
    "\n",
    "precisionContent_rank, recallContent_rank, f1Content_rank = get_rec_accuracy(topTestIDs, topContentIDs, numTest, rec_rank=True)\n",
    "print \"Content-based Accuracy - Including Recommendation Rank\"\n",
    "print \"Precision: %.2f\" %precisionContent_rank\n",
    "print \"Recall: %.2f\" %recallContent_rank\n",
    "print \"F1 score: %.2f\\n\" %f1Content_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All users accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = range(1,100)\n",
    "users = range(1, numUsers + 1)\n",
    "random.shuffle(users)\n",
    "users = users[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_accuracy_50 = pd.DataFrame(index=users, columns=['precision_cf', 'recall_cf', 'f1_cf', \n",
    "                                                  'precision_cb', 'recall_cb', 'f1_cb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "topN = 0.5 #top N percent of recommendations\n",
    "for u in users:\n",
    "    trainSet, trainIDs, testSet, testIDs, n = make_traintest_sets(u, topN)\n",
    "    topTestIDs, topCFIDs, topContentIDs = get_top_recommendations(u, testSet, testIDs, n)\n",
    "    num_test = len(testIDs)\n",
    "    pcf, rcf, f1cf = get_rec_accuracy(topTestIDs, topCFIDs, numTest, rec_rank=False)\n",
    "    pcb, rcb, f1cb = get_rec_accuracy(topTestIDs, topContentIDs, numTest, rec_rank=False)\n",
    "    \n",
    "    compare_accuracy_50.ix[u] = np.array([pcf, rcf, f1cf, pcb, rcb, f1cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_cf</th>\n",
       "      <th>recall_cf</th>\n",
       "      <th>f1_cf</th>\n",
       "      <th>precision_cb</th>\n",
       "      <th>recall_cb</th>\n",
       "      <th>f1_cb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9782</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19282</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20787</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18020</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13647</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22461</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8160</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18872</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12316</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10776</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7010</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7673</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13890</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10424</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22340</th>\n",
       "      <td>1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12960</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17042</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18923</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14376</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13209</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16226</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13117</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21924</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12847</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18490</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20693</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18863</th>\n",
       "      <td>1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13090</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13145</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12706</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14942</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8448</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23293</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20924</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16737</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8627</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  6 columns</p>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "compare_accuracy_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision_cf    0.6711\n",
       "recall_cf       0.2553\n",
       "f1_cf           0.3631\n",
       "precision_cb    0.7327\n",
       "recall_cb       0.2817\n",
       "f1_cb           0.3997\n",
       "dtype: float64"
      ]
     },
     "execution_count": 872,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Average accuracy scores\n",
    "compare_accuracy_50.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 863,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Percentage where CF > CB F1 scores\n",
    "len(compare_accuracy[compare_accuracy.f1_cf > compare_accuracy.f1_cb]) / float(len(compare_accuracy.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 864,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(compare_accuracy[compare_accuracy.f1_cf == compare_accuracy.f1_cb]) / float(len(compare_accuracy.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 865,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(compare_accuracy[compare_accuracy.f1_cf < compare_accuracy.f1_cb]) / float(len(compare_accuracy.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CB better than CF?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Error = 0.692820323028\n"
     ]
    }
   ],
   "source": [
    "# Documentation example\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "\n",
    "data = sc.textFile(\"/home/brian/workspace/cuny_msda_is622/spark-1.5.1-bin-hadoop2.6/data/mllib/kmeans_data.txt\")\n",
    "parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n",
    "# Build the model (cluster the data)\n",
    "clusters = KMeans.train(parsedData, 2, maxIterations=10,\n",
    "        runs=10, initializationMode=\"random\")\n",
    "\n",
    "# Evaluate clustering by computing Within Set Sum of Squared Errors\n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    return sqrt(sum([x**2 for x in (point - center)]))\n",
    "\n",
    "WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "print(\"Within Set Sum of Squared Error = \" + str(WSSSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code below is k-means on joke features sparse vectors\n",
    "# TAKES FOREVER TO RUN\n",
    "# joke_features_par = sc.parallelize(joke_features)\n",
    "\n",
    "# joke_clusters = KMeans.train(joke_features_par, 5, maxIterations=2,\n",
    "#         runs=2, initializationMode=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means cluster users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpd_kmeans_user = jpd.iloc[:,1:]\n",
    "jdf_kmeans_user = sqlc.createDataFrame(jpd_kmeans_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from numpy import array\n",
    "\n",
    "k = 10 # number of clusters\n",
    "user_kmeans = jdf_kmeans_user.map(lambda row: array([x for x in row]))\n",
    "user_clusters = KMeans.train(user_kmeans, k, maxIterations=10, seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict cluster of each user\n",
    "user_kmeans_predict = user_clusters.predict(user_kmeans).take(user_kmeans.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Counter({5: 4061, 3: 3895, 8: 2717, 1: 2617, 0: 2372, 4: 1982, 9: 1980, 7: 1930, 2: 1720, 6: 1709})\n"
     ]
    }
   ],
   "source": [
    "# Examine output\n",
    "print user_kmeans_predict[0]\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(user_kmeans_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16987.183085482116"
      ]
     },
     "execution_count": 960,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Sum of squares distance\n",
    "user_clusters.computeCost(user_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means cluster jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpd_kmeans_jokes = jpd_kmeans_user.transpose()\n",
    "jdf_kmeans_jokes = sqlc.createDataFrame(jpd_kmeans_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "jokes_kmeans = jdf_kmeans_jokes.map(lambda row: array([x for x in row]))\n",
    "jokes_clusters = KMeans.train(jokes_kmeans, k, maxIterations=10, seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict cluster of each user\n",
    "jokes_kmeans_predict = jokes_clusters.predict(jokes_kmeans).take(jokes_kmeans.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Counter({2: 63, 0: 34, 1: 1, 3: 1, 4: 1})\n"
     ]
    }
   ],
   "source": [
    "# Examine output\n",
    "print jokes_kmeans_predict[0]\n",
    "print(Counter(jokes_kmeans_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17584.067350474736"
      ]
     },
     "execution_count": 965,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Sum of squares distance\n",
    "jokes_clusters.computeCost(jokes_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_features_par = sc.parallelize(joke_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 11 words):\n",
      "Topic 0:\n",
      " 6.06242933367\n",
      " 6.63111741428\n",
      " 4.41304546174\n",
      " 32.6199586258\n",
      " 3.95014154544\n",
      " 2.64793546749\n",
      " 4.3003806703\n",
      " 0.857599216182\n",
      " 1.68984316352\n",
      " 8.65447369017\n",
      " 13.8611214153\n",
      "Topic 1:\n",
      " 7.75583529139\n",
      " 7.50220399212\n",
      " 2.53054294983\n",
      " 4.6897212649\n",
      " 3.02407120052\n",
      " 5.36259463874\n",
      " 24.5954891441\n",
      " 1.34266914869\n",
      " 4.97476762903\n",
      " 7.49788766678\n",
      " 16.5623160588\n",
      "Topic 2:\n",
      " 12.1817353749\n",
      " 14.8666785936\n",
      " 5.05641158843\n",
      " 2.69032010931\n",
      " 18.025787254\n",
      " 13.9894698938\n",
      " 2.10413018563\n",
      " 7.79973163513\n",
      " 1.33538920746\n",
      " 7.84763864306\n",
      " 2.57656252588\n"
     ]
    }
   ],
   "source": [
    "# Documentation example\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# Load and parse the data\n",
    "data = sc.textFile(\"/home/brian/workspace/cuny_msda_is622/spark-1.5.1-bin-hadoop2.6/data/mllib/sample_lda_data.txt\")\n",
    "parsedData = data.map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\n",
    "# Index documents with unique IDs\n",
    "corpus = parsedData.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()\n",
    "\n",
    "# Cluster the documents into three topics using LDA\n",
    "ldaModel = LDA.train(corpus, k=3)\n",
    "\n",
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize()) + \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(3):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'zipWithIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-976-6f804c7c7826>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# parsedData = data.map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Index documents with unique IDs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoke_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzipWithIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Cluster the documents into three topics using LDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'zipWithIndex'"
     ]
    }
   ],
   "source": [
    "# LDA for joke features\n",
    "\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# Load and parse the data\n",
    "# data = sc.textFile(\"/home/brian/workspace/cuny_msda_is622/spark-1.5.1-bin-hadoop2.6/data/mllib/sample_lda_data.txt\")\n",
    "# parsedData = data.map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\n",
    "# Index documents with unique IDs\n",
    "\n",
    "corpus = joke_features.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()\n",
    "\n",
    "# Cluster the documents into three topics using LDA\n",
    "ldaModel = LDA.train(corpus, k=3)\n",
    "\n",
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize()) + \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(3):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}